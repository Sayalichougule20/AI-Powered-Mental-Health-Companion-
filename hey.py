import os
import librosa
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wav
import streamlit as st
import random
import nltk
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
import speech_recognition as sr
import io

st.set_page_config(page_title="EmotiCare - Emotion Based AI Chatbot", 
                   page_icon="üéôÔ∏è", 
                   layout="centered")

# Download NLTK resources
nltk.download('vader_lexicon', quiet=True)

# Load BERT model and tokenizer
BERT_MODEL_PATH = "bert_emotion_model"

try:
    tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_PATH)
    model.eval()
    st.success("‚úÖ BERT emotion model loaded successfully!")
except Exception as e:
    st.error(f"‚ùå Failed to load BERT emotion model: {e}")

# Emotion labels (customize as per your model training order)
bert_emotion_labels = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']

emotion_responses = {
    "anger": ["I understand. Take a deep breath. Want some help calming down?", "Try some relaxation techniques!"],
    "fear": ["It's okay to feel scared. Want to talk about it?", "Fear is natural. Take a deep breath."],
    "joy": ["That's wonderful! üòä Let's keep the good vibes going!", "Joy is a beautiful feeling. Celebrate it!"],
    "love": ["That's heartwarming! Spread the love üíñ", "Love makes the world brighter. Tell someone you care!"],
    "sadness": ["I'm here for you. Want to talk about it? üíô", "Things will get better. Stay strong!"],
    "surprise": ["Oh wow! That sounds interesting!", "Surprises can be exciting! Want to share more?"]
}

video_links = {
    "anger": "https://youtu.be/66gH1xmXkzI?si=zDv3BIHqQqXYlEqx",
    "fear": "https://youtu.be/AETFvQonfV8?si=h7JWyBwTyYPKwqtc",
    "joy": "https://youtu.be/OcmcptbsvzQ?si=hUQtzH0vRyGV5hmK",  # same as happy
    "love": "https://youtu.be/UAaWoz9wJ_4?si=Qktt7mDUXRmFda5t",  # used calm/loving video
    "sadness": "https://youtu.be/W937gFzsD-c?si=aT3DcRssJRdF0SeH",
    "surprise": "https://youtu.be/PE2GkSgOZMA?si=yZwanX7PC16C73SG"
}

# ---------------- Functions ----------------

def speech_to_text_from_audio(audio_data):
    recognizer = sr.Recognizer()
    with sr.AudioData(audio_data.tobytes(), 16000, 2) as source_audio:
        try:
            text = recognizer.recognize_google(source_audio)
            return text
        except sr.UnknownValueError:
            return None

def predict_bert_emotion(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    scores = softmax(outputs.logits.numpy()[0])
    top_index = np.argmax(scores)
    return bert_emotion_labels[top_index]

def generate_response(emotion):
    return random.choice(emotion_responses.get(emotion, ["I'm here to chat! üòä"]))

def record_audio(duration=5, samplerate=16000):
    """ Record audio using sounddevice library and specify input device """
    st.write("üéôÔ∏è Recording your voice...")

    # List available devices and check if there are any input devices
    devices = sd.query_devices()
    if not devices:  # If no devices are found
        st.error("‚ö†Ô∏è No audio input devices found. Please check your microphone.")
        return None

    # Display available devices for debugging
    st.write(devices)  # Print devices in Streamlit UI

    # Try to select the first available input device
    try:
        input_device = devices[0]['name']  # Replace with the correct index if needed
        st.write(f"Selected device: {input_device}")
    except IndexError:
        st.error("‚ö†Ô∏è No input device found.")
        return None

    # Record audio
    try:
        audio_data = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16', device=input_device)
        sd.wait()  # Wait until recording is finished
        return audio_data
    except Exception as e:
        st.error(f"‚ö†Ô∏è Error recording audio: {e}")
        return None

# ---------------- UI ----------------

st.markdown("""
    <style>
    .stApp { background: linear-gradient(to right, #FFDEE9, #B5FFFC); font-family: 'Arial', sans-serif; }
    .title { color: #ff4b5c; font-size: 36px; font-weight: bold; text-align: center; }
    .subtitle { color: #333; font-size: 18px; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

st.markdown('<p class="title">üéôÔ∏è EmotiCare - Emotion Based AI Chatbot</p>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">Detect emotions from your voice or text and receive personalized responses!</p>', unsafe_allow_html=True)

st.sidebar.title("üîç Choose Input Method")
input_type = st.sidebar.radio("", ["Text", "Voice"])

if input_type == "Text":
    user_text = st.text_input("üí¨ Type your message:")
    if st.button("Analyze Emotion üé≠"):
        if user_text:
            with st.spinner("üîç Analyzing Emotion..."):
                detected_emotion = predict_bert_emotion(user_text)
            st.markdown(f"### üé≠ Detected Emotion: **{detected_emotion.capitalize()}**")
            st.success(f"ü§ñ Chatbot: {generate_response(detected_emotion)}")
            if detected_emotion in video_links:
                st.video(video_links[detected_emotion])
        else:
            st.warning("‚ö†Ô∏è Please enter some text.")

elif input_type == "Voice":
    st.write("üéôÔ∏è Record your voice:")
    
    if st.button("Start Recording"):
        audio_data = record_audio(duration=5)  # Record for 5 seconds
        if audio_data is not None:
            st.write("üéß Processing your audio...")

            # Convert audio to text
            audio_bytes = io.BytesIO(audio_data.tobytes())  # Convert to a BytesIO object for recognition
            text = speech_to_text_from_audio(audio_bytes)
            
            if text:
                st.markdown(f"### üìù **Transcribed Text:** _{text}_")
                detected_emotion = predict_bert_emotion(text)
                st.markdown(f"### üé≠ Detected Emotion: **{detected_emotion.capitalize()}**")
                st.success(f"ü§ñ Chatbot: {generate_response(detected_emotion)}")
                if detected_emotion in video_links:
                    st.video(video_links[detected_emotion])
            else:
                st.warning("‚ö†Ô∏è Could not detect any speech. Please try again.")
